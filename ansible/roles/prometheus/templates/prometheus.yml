---
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  scrape_timeout:      15s

# the path is absolute as ansible `validates` temporary file in some temporary directory
rule_files:
  - "/etc/prometheus/alert_rules.yml"
  - "/etc/prometheus/alert_ooni.yml"

alerting:
  alertmanagers:
  - static_configs:
    - targets: [ '127.0.0.1:9093' ]

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.

  # Node exporter metrics
{% for bbjob in blackbox_jobs %}
  - job_name: "{{ bbjob.name }}"
    metrics_path: /probe
    params:
      module:
        - "{{ bbjob.module }}"
    static_configs:
      - targets:
{% for target in (bbjob.targets|sort) %}
        - "{{ target }}"
{% endfor %}
    relabel_configs:
      - source_labels: [__address__]
        regex: (.*)(:80)?
        target_label: __param_target
        replacement: ${1}
      - source_labels: [__param_target]
        regex: (.*)
        target_label: instance
        replacement: ${1}
      - source_labels: []
        regex: .*
        target_label: __address__
        replacement: 127.0.0.1:9115
{% endfor %}

  - job_name: 'node'
    scrape_interval: 5s
    scheme: https
    tls_config:
      ca_file: "{{ prometheus_exporter_cert }}"
      cert_file: "{{ prometheus_ssl_dir }}/{{ inventory_hostname }}.chain"
      key_file: "{{ prometheus_ssl_dir }}/{{ inventory_hostname }}.key"
      # XXX this is a hotfix to https://github.com/ooni/backend/issues/747
      insecure_skip_verify: true
    static_configs:
      - targets:
{% for host in (dom0_hosts|sort) %}
        - {{ host }}:9100
{% endfor %}

  - job_name: 'node_exporter'
    scrape_interval: 5s
    basic_auth:
      username: 'prom'
      password: '{{ prometheus_metrics_password_prod }}'
    static_configs:
      - targets:
        - https://data1.htz-fsn.prod.ooni.nu/metrics/node_exporter
        - https://data3.htz-fsn.prod.ooni.nu/metrics/node_exporter
        - https://notebook1.htz-fsn.prod.ooni.nu/metrics/node_exporter
        - http://0.do.th.prod.ooni.io:9001/metrics
        - http://1.do.th.prod.ooni.io:9001/metrics
        - http://2.do.th.prod.ooni.io:9001/metrics
    relabel_configs:
        # set the scheme based on what has been parsed in the address
      - source_labels: [__address__]
        regex: '(https|http)://([^/^:]+)(:\d+)?(/.*)'
        replacement: '$1'
        target_label: __scheme__
        # set the path based on the address suffix
      - source_labels: [__address__]
        regex: '(https|http)://([^/^:]+)(:\d+)?(/.*)'
        replacement: '$4'
        target_label: __metrics_path__
        # set the instance name to the address without the port
      - source_labels: [__address__]
        regex: '(https|http)://([^/^:]+)(:\d+)?(/.*)'
        replacement: '$2'
        target_label: instance
        # set the environment label to prod or dev
      - source_labels: [instance]
        regex: '.*\.(prod|dev)\..*'
        replacement: '$1'
        target_label: environment
      - source_labels: [environment]
        regex: '^$'
        replacement: 'prod'
        target_label: environment
        # cleanup the address to only contain the fqdn:port
      - source_labels: [__address__]
        regex: '(https|http)://([^/]+)(:\d+)?(/.*)'
        replacement: '$2$3'
        target_label: __address__

# TODO: should this be re-enabled?
#  - job_name: 'netdata'
#    scrape_interval: 5s
#    scheme: https
#    metrics_path: /api/v1/allmetrics
#    params:
#      format: [prometheus]
#    tls_config:
#      ca_file: "{{ prometheus_exporter_cert }}"
#      cert_file: "{{ prometheus_ssl_dir }}/{{ inventory_hostname }}.chain"
#      key_file: "{{ prometheus_ssl_dir }}/{{ inventory_hostname }}.key"
#    static_configs:
#      - targets:

  # Application level metrics

  - job_name: 'clickhouse'
    scrape_interval: 5s
    scheme: http
    metrics_path: "/metrics"
    static_configs:
      - targets:
        - backend-fsn.ooni.org:9363

  - job_name: 'clickhouse-cluster'
    scrape_interval: 5s
    scheme: https
    metrics_path: "/metrics/clickhouse"
    basic_auth:
      username: 'prom'
      password: '{{ prometheus_metrics_password_prod }}'
    static_configs:
      - targets:
        - data1.htz-fsn.prod.ooni.nu
        - data3.htz-fsn.prod.ooni.nu
        - notebook1.htz-fsn.prod.ooni.nu

  - job_name: 'raw-netdata'
    scrape_interval: 5s
    scheme: http
    metrics_path: "/api/v1/allmetrics"
    params:
      format: [prometheus]
    static_configs:
      - targets:
        - backend-fsn.ooni.org:19999
        - backend-hel.ooni.org:19999

  - job_name: 'ooni-api'
    scrape_interval: 5s
    scheme: https
    static_configs:
      - targets: [ 'api.ooni.io:443' ]

  - job_name: 'ooniapi-services'
    scrape_interval: 5s
    scheme: https
    metrics_path: "/metrics"
    basic_auth:
      username: 'prom'
      password: '{{ prometheus_metrics_password_prod }}'
    static_configs:
      - targets:
        - ooniauth.prod.ooni.io
        - oonirun.prod.ooni.io
        - ooniprobe.prod.ooni.io
        # these require a different password. Probably we should update them to
        # take the same one for the purpose of monitoring.
        # - ooniauth.dev.ooni.io
        # - oonirun.dev.ooni.io
        # - ooniprobe.dev.ooni.io
    relabel_configs:
      - source_labels: [__address__]
        regex: "(prod|dev)"
        target_label: environment
        replacement: "$1"

  - job_name: 'oonith'
    scrape_interval: 5s
    scheme: http
    metrics_path: "/metrics"
    basic_auth:
      username: 'prom'
      password: '{{ prometheus_metrics_password_prod }}'
    static_configs:
      - targets:
        - 0.do.th.prod.ooni.io
        - 1.do.th.prod.ooni.io
        - 2.do.th.prod.ooni.io
  - job_name: 'ooni-web'
    scrape_interval: 5m
    scheme: https
    metrics_path: /_web.mtime.txt
    static_configs:
    - targets: # all mirrors listed in https://github.com/TheTorProject/ooni-web#ooni-web
      - ooni.io:443
      - ooni.torproject.org:443
      - openobservatory.github.io:443
      - ooni.netlify.app:443


  # See ansible/roles/ooni-backend/tasks/main.yml for the scraping targets
  - job_name: 'haproxy'
    scrape_interval: 5s
    scheme: https
    metrics_path: "/__haproxy_prom_metrics"
    static_configs:
      - targets:
        - backend-hel.ooni.org:444

  # EC2 instances monitoring: 
  - job_name: 'ooni-aws-ec2'
    scrape_interval: 5s
    scheme: https 
    metrics_path: "/metrics" 

    # Node level metrics for cluster nodes
    ec2_sd_configs:
      - access_key: "{{prometheus_aws_access_key_dev}}" 
        secret_key: "{{prometheus_aws_secret_key_dev}}"
        region: "eu-central-1"
        port: 9100 # should be the proxy 
    relabel_configs: # Change the host to the proxy host with relabeling
      - source_labels: [__address__]
        regex: "([0-9\\.]+):([0-9]+)" # <ip>:<port>"
        replacement: "$1"
        target_label: "ec2_host"
        action: "replace"
      - source_labels: [__address__]
        regex: "([0-9\\.]+):([0-9]+)" # <ip>:<port>
        replacement: "{{clickhouse_proxy_host_dev}}:9200/${1}/${2}/metrics"
        target_label: "proxy_host"
        action: "replace"
      - source_labels: [proxy_host]
        regex: "([^/]*)/(.*)"
        replacement: "$1"
        target_label: "__address__"
        action: "replace"
      - source_labels: [proxy_host]
        regex: "([^/]*)/(.*)"
        replacement: "/$2"
        target_label: "__metrics_path__"
        action: "replace"

  # Scrape tasks in ECS using file based discovery, useful for application level metrics
  - job_name: "ecs-tasks-dev"
    scrape_interval: 5s
    scheme: https
    basic_auth:
      username: 'prom'
      password: '{{ prometheus_metrics_password_dev }}'
    file_sd_configs:
      - files: 
        - '/var/lib/prometheus/file_discovery/*.json'
    relabel_configs: # Change the host to the proxy host with relabeling
      # Store ip in ecs_host
      - source_labels: [__address__]
        regex: "([0-9\\.]+):([0-9]+)" # <ip>:<port>"
        replacement: "$1"
        target_label: "ec2_host"
        action: "replace"
      # Store the full adress with path in proxy_host
      - source_labels: [__address__]
        regex: "([0-9\\.]+):([0-9]+)" # <ip>:<port>
        replacement: "{{clickhouse_proxy_host_dev}}:9200/${1}/${2}/metrics" # proxy.org:9200/<private_ip>/<port>/metrics
        target_label: "proxy_host"
        action: "replace"
      # Change the address where to send the scrape request to
      - source_labels: [proxy_host]
        regex: "([^/]*)/(.*)"
        replacement: "$1"
        target_label: "__address__"
        action: "replace"
      # Change the metrics path to include ip address and /metrics path
      - source_labels: [proxy_host]
        regex: "([^/]*)/(.*)"
        replacement: "/$2"
        target_label: "__metrics_path__"
        action: "replace"
...
